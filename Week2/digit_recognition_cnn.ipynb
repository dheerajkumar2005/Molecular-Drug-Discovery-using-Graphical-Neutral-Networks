{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_set.data.shape)\n",
    "print(test_set.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,10,5)\n",
    "        self.conv2 = nn.Conv2d(10,20,5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu((F.max_pool2d(self.conv1(x),2)))\n",
    "        x = F.relu((F.max_pool2d(self.conv2_drop(self.conv2(x)),2)))\n",
    "        x = x.view(-1,320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x,training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(test_loader):\n",
    "        data,target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)} / {len(train_loader.dataset)} ({100 * batch_idx / len(train_loader):0f}%)]\\t{loss.item():.6f}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            data,target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output,target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss: 0.4f}, Accuracy {correct}/{len(test_loader.dataset)}  ({100 * correct / len(test_loader.dataset):.0f}%\\n)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1649133/2312631035.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0 / 60000 (0.000000%)]\t2.302935\n",
      "Train Epoch: 1 [2000 / 60000 (3.333333%)]\t2.286932\n",
      "Train Epoch: 1 [4000 / 60000 (6.666667%)]\t2.041288\n",
      "Train Epoch: 1 [6000 / 60000 (10.000000%)]\t2.016140\n",
      "Train Epoch: 1 [8000 / 60000 (13.333333%)]\t1.882420\n",
      "\n",
      "Test set: Average loss:  0.0172, Accuracy 7533/10000  (75%\n",
      "\n",
      "Train Epoch: 2 [0 / 60000 (0.000000%)]\t1.778316\n",
      "Train Epoch: 2 [2000 / 60000 (3.333333%)]\t1.850412\n",
      "Train Epoch: 2 [4000 / 60000 (6.666667%)]\t1.757574\n",
      "Train Epoch: 2 [6000 / 60000 (10.000000%)]\t1.770336\n",
      "Train Epoch: 2 [8000 / 60000 (13.333333%)]\t1.696649\n",
      "\n",
      "Test set: Average loss:  0.0161, Accuracy 8690/10000  (87%\n",
      "\n",
      "Train Epoch: 3 [0 / 60000 (0.000000%)]\t1.692958\n",
      "Train Epoch: 3 [2000 / 60000 (3.333333%)]\t1.719262\n",
      "Train Epoch: 3 [4000 / 60000 (6.666667%)]\t1.717839\n",
      "Train Epoch: 3 [6000 / 60000 (10.000000%)]\t1.717695\n",
      "Train Epoch: 3 [8000 / 60000 (13.333333%)]\t1.608770\n",
      "\n",
      "Test set: Average loss:  0.0158, Accuracy 8947/10000  (89%\n",
      "\n",
      "Train Epoch: 4 [0 / 60000 (0.000000%)]\t1.655985\n",
      "Train Epoch: 4 [2000 / 60000 (3.333333%)]\t1.747958\n",
      "Train Epoch: 4 [4000 / 60000 (6.666667%)]\t1.653320\n",
      "Train Epoch: 4 [6000 / 60000 (10.000000%)]\t1.654351\n",
      "Train Epoch: 4 [8000 / 60000 (13.333333%)]\t1.598909\n",
      "\n",
      "Test set: Average loss:  0.0156, Accuracy 9024/10000  (90%\n",
      "\n",
      "Train Epoch: 5 [0 / 60000 (0.000000%)]\t1.667811\n",
      "Train Epoch: 5 [2000 / 60000 (3.333333%)]\t1.715238\n",
      "Train Epoch: 5 [4000 / 60000 (6.666667%)]\t1.625306\n",
      "Train Epoch: 5 [6000 / 60000 (10.000000%)]\t1.647046\n",
      "Train Epoch: 5 [8000 / 60000 (13.333333%)]\t1.541357\n",
      "\n",
      "Test set: Average loss:  0.0154, Accuracy 9203/10000  (92%\n",
      "\n",
      "Train Epoch: 6 [0 / 60000 (0.000000%)]\t1.637620\n",
      "Train Epoch: 6 [2000 / 60000 (3.333333%)]\t1.712236\n",
      "Train Epoch: 6 [4000 / 60000 (6.666667%)]\t1.649608\n",
      "Train Epoch: 6 [6000 / 60000 (10.000000%)]\t1.666846\n",
      "Train Epoch: 6 [8000 / 60000 (13.333333%)]\t1.559192\n",
      "\n",
      "Test set: Average loss:  0.0154, Accuracy 9262/10000  (93%\n",
      "\n",
      "Train Epoch: 7 [0 / 60000 (0.000000%)]\t1.598634\n",
      "Train Epoch: 7 [2000 / 60000 (3.333333%)]\t1.696187\n",
      "Train Epoch: 7 [4000 / 60000 (6.666667%)]\t1.628189\n",
      "Train Epoch: 7 [6000 / 60000 (10.000000%)]\t1.642011\n",
      "Train Epoch: 7 [8000 / 60000 (13.333333%)]\t1.566664\n",
      "\n",
      "Test set: Average loss:  0.0153, Accuracy 9280/10000  (93%\n",
      "\n",
      "Train Epoch: 8 [0 / 60000 (0.000000%)]\t1.595510\n",
      "Train Epoch: 8 [2000 / 60000 (3.333333%)]\t1.675462\n",
      "Train Epoch: 8 [4000 / 60000 (6.666667%)]\t1.624565\n",
      "Train Epoch: 8 [6000 / 60000 (10.000000%)]\t1.622611\n",
      "Train Epoch: 8 [8000 / 60000 (13.333333%)]\t1.557294\n",
      "\n",
      "Test set: Average loss:  0.0153, Accuracy 9330/10000  (93%\n",
      "\n",
      "Train Epoch: 9 [0 / 60000 (0.000000%)]\t1.596959\n",
      "Train Epoch: 9 [2000 / 60000 (3.333333%)]\t1.654530\n",
      "Train Epoch: 9 [4000 / 60000 (6.666667%)]\t1.600632\n",
      "Train Epoch: 9 [6000 / 60000 (10.000000%)]\t1.617774\n",
      "Train Epoch: 9 [8000 / 60000 (13.333333%)]\t1.549815\n",
      "\n",
      "Test set: Average loss:  0.0153, Accuracy 9354/10000  (94%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "general_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
