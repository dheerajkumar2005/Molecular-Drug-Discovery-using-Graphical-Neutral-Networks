

### Week 2: Understanding Advanced Neural Networks and Graph Neural Networks
**Note:** - the content of week2 will get updated and organized after halfway point of Week 1. if you are comfortable with week 1, then you can go through GNN articles provided.


**Part 1(Neural Networks and CNN) (till 23rd December)**
- **Resources**: 
  - To get the intuition of ReLU activation, read this article: [Visualizing Piecewise Linear Neural Networks](https://blog.janestreet.com/visualizing-piecewise-linear-neural-networks/).
  - Go over this [Coursera course](https://www.coursera.org/learn/neural-networks-deep-learning) to learn more about neural networks.

### Linear Algebra (if you are uncomfortable with matrices stuff)
- If you feel uncomfortable with the matrices stuff in algorithms, you can refer to this for basic notations https://www.geeksforgeeks.org/ml-linear-algebra-operations/
- Here are MA110 course [slides]() to get in more depth.
- Some important matrix operations:-
  - https://atmos.washington.edu/~dennis/MatrixCalculus.pdf,
  - https://explained.ai/matrix-calculus/

### Understanding Basics of CNN 
 - https://www.datacamp.com/tutorial/introduction-to-convolutional-neural-networks-cnns
 - https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148
 - https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning (optional, you can refer to it to get to more depth and also various famous CNN architectures)

**Assignment (deadline: 23 Dec)**
 - Implement convolutional neural network to classify digits on MNIST dataset using pytorch(refer to week 1 [optional tutorials](https://youtu.be/c36lUUr864M?si=ipK9wX2L0EgOtZHV) to understand pytorch syntax)
 - **(optional)** Go through the object detection section in this [course](https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning), and implement object detection model on pascal voc dataset. 
 - Main idea is to get the intuition of how CNN works, you can do experimentation and play with various parameters to get more understanding.
--- 

**Part 2(Graphical Neural Networks and related stuff)(more resources and assignments will be added here soon)**

### Introduction to Graph Data Structure
- [Graph Data Structure - tutorialspoint](https://www.tutorialspoint.com/data_structures_algorithms/graph_data_structure.htm) (till representation of graph)

### Graph representation in Machine learning 
  -  [Unsupervised Node Embedding](https://web.stanford.edu/class/cs224w/slides/02-nodeemb.pdf)
  
### Introduction to GNN
  -  [Understanding GNNs](https://distill.pub/2021/understanding-gnns/)
  - https://medium.com/@tejpal.abhyuday/introduction-to-graph-neural-networks-gnns-f79ca974a57d

### GCN
  - https://web.stanford.edu/class/cs224w/slides/03-GNN1.pdf

### GNN Layer, Layer connectivity and Graph Manipulation :
  - https://web.stanford.edu/class/cs224w/slides/04-GNN2.pdf

### Hands-on with karateclub dataset
  - https://towardsdatascience.com/graph-convolutional-networks-introduction-to-gnns-24b3f60d6c95

#### For Graph Neural Networks
- **Articles for Basic Ideas**:
  - [Neptune.ai: Graph Neural Network and Some of GNN Applications](https://neptune.ai/blog/graph-neural-network-and-some-of-gnn-applications)
  <!-- - [Towards Data Science: Graph Convolutional Networks](https://towardsdatascience.com/graph-convolutional-networks-introduction-to-gnns-24b3f60d6c95) -->

- **Optional Readings**:
  - Read and understand the research paper: [Neural Message Passing for Quantum Chemistry](https://arxiv.org/pdf/1704.01212).
  - Read this article on how to use Graphical Neural Networks in drug discovery: [Drug Discovery and Graph Neural Networks](https://medium.com/@mulugetas/drug-discovery-and-graph-neural-networks-gnns-a-regression-example-fc738e0f11f3).

#### Tutorials and Videos
- [YouTube: Graph Neural Networks Introduction](https://www.youtube.com/watch?v=8owQBFAHw7E)
- [YouTube Playlist: Graph Neural Networks](https://youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn&si=GiLMZdfS5szrhH0z)
