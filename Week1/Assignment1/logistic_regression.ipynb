{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4238 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4235     0   48        2.0              1        20.0     NaN   \n",
       "4236     0   44        1.0              1        15.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4235                0             0         0    248.0  131.0   72.0  22.00   \n",
       "4236                0             0         0    210.0  126.5   87.0  19.16   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4233       66.0     86.0           1  \n",
       "4234       65.0     68.0           0  \n",
       "4235       84.0     86.0           0  \n",
       "4236       86.0      NaN           0  \n",
       "4237       80.0    107.0           0  \n",
       "\n",
       "[4238 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('framingham.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.96</td>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4231     1   58        3.0              0         0.0     0.0   \n",
       "4232     1   68        1.0              0         0.0     0.0   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4231                0             1         0    187.0  141.0   81.0  24.96   \n",
       "4232                0             1         0    176.0  168.0   97.0  23.14   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4231       80.0     81.0           0  \n",
       "4232       60.0     79.0           1  \n",
       "4233       66.0     86.0           1  \n",
       "4234       65.0     68.0           0  \n",
       "4237       80.0    107.0           0  \n",
       "\n",
       "[3656 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = data.dropna()\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3290, 16) (366, 16)\n"
     ]
    }
   ],
   "source": [
    "train_data = cleaned_data.sample(frac=0.9,random_state=42)\n",
    "test_data  = cleaned_data.drop(train_data.index)\n",
    "print(train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3290, 15) (3290,) (366, 15) (366,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.iloc[:,0:15].to_numpy()\n",
    "Y_train = train_data.iloc[:,15].to_numpy()\n",
    "X_test = test_data.iloc[:,0:15].to_numpy()\n",
    "Y_test = test_data.iloc[:,15].to_numpy()\n",
    "print(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "X_test_scaled = (X_test - np.mean(X_train))/np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self,X):\n",
    "        self.w = np.random.rand(X.shape[1])\n",
    "        self.b = np.random.rand()\n",
    "    def sigmoid(self,X):\n",
    "        return 1/(1+np.exp(-X))\n",
    "    def predict(self,X):\n",
    "        return self.sigmoid(np.dot(X,self.w)+self.b)\n",
    "    \n",
    "    def gradient(self,X,Y):\n",
    "        dw = np.matmul(X.T,self.predict(X)-Y)/X.shape[0]\n",
    "        db = np.mean(self.predict(X)-Y)\n",
    "        return dw,db\n",
    "    def update_weights(self,dw,db,lr):\n",
    "        self.w = self.w - lr*dw\n",
    "        self.b = self.b - lr*db\n",
    "\n",
    "    def cost(self,X,Y):\n",
    "        return -np.mean(Y*np.log(self.predict(X))+(1-Y)*np.log(1-self.predict(X)))\n",
    "    def fit(self,X,Y,lr,epochs):\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            dw,db = self.gradient(X,Y)\n",
    "            self.update_weights(dw,db,lr)\n",
    "            if ((i+1)%100==0):print(f'Epoch {i+1}/{epochs} Cost: {self.cost(X,Y)} Weights: {self.w} Bias: {self.b}')\n",
    "    def accuracy(self,X,Y):\n",
    "        \n",
    "        percentage_correctly_classified =  np.mean(np.round(self.predict(X))==Y)*100\n",
    "        false_negatives = np.sum((Y == 1) & (np.round(self.predict(X)) == 0))\n",
    "        false_positives = np.sum((Y == 0) & (np.round(self.predict(X)) == 1))\n",
    "        percentage_false_negatives = false_negatives/np.sum(Y == 1)*100\n",
    "        percentage_false_positives = false_positives/np.sum(Y == 0)*100\n",
    "        \n",
    "        print(f'Accuracy: {percentage_correctly_classified}% False Negatives: {percentage_false_negatives}% False Positives: {percentage_false_positives}%')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/4000 Cost: 0.40292353232526956 Weights: [ 0.44380859  0.90819936  0.69836786  1.03823065  0.84147256  0.82532308\n",
      "  0.6778066   0.36912057  0.96560032  0.16064967  1.13701542  0.2157675\n",
      "  1.12822325 -0.04356037  0.56883221] Bias: 0.43335059131798354\n",
      "Epoch 200/4000 Cost: 0.3951521345555742 Weights: [ 0.49698828  1.44435183  0.71002702  1.07604725  1.04757542  0.85877522\n",
      "  0.71001156  0.41020717  0.99779617  0.17915673  1.29010624  0.12335506\n",
      "  1.12434464 -0.17038321  0.59534634] Bias: 0.38875517410211263\n",
      "Epoch 300/4000 Cost: 0.39104309528453074 Weights: [ 0.51145024  1.88052844  0.68671563  1.07500303  1.19362572  0.85295924\n",
      "  0.70335339  0.4101879   0.99083021  0.16653831  1.33406148  0.02148951\n",
      "  1.09770238 -0.24922762  0.59134217] Bias: 0.40004578757261494\n",
      "Epoch 400/4000 Cost: 0.38860545583887396 Weights: [ 0.51793181  2.24787259  0.65741243  1.06584783  1.30780182  0.83936375\n",
      "  0.68903497  0.40192036  0.97613086  0.14799729  1.34379353 -0.06448346\n",
      "  1.0696099  -0.29953417  0.58396616] Bias: 0.422335979745449\n",
      "Epoch 500/4000 Cost: 0.3871889396568853 Weights: [ 0.52401048  2.56127683  0.62908398  1.05620507  1.40048196  0.825727\n",
      "  0.67470922  0.3935156   0.96140136  0.13160133  1.34270662 -0.13077038\n",
      "  1.04482905 -0.33150201  0.57783271] Bias: 0.44462098259837596\n",
      "Epoch 600/4000 Cost: 0.38632026003386566 Weights: [ 0.53098001  2.8302225   0.60274685  1.04740865  1.47664276  0.81333738\n",
      "  0.66163886  0.3863515   0.94791657  0.1205686   1.33851986 -0.17929218\n",
      "  1.02371093 -0.35119241  0.57369218] Bias: 0.4650883606390358\n",
      "Epoch 700/4000 Cost: 0.3857106525990293 Weights: [ 0.53922725  3.06164051  0.57860111  1.03987328  1.53979119  0.80254282\n",
      "  0.65016525  0.38078198  0.9360195   0.11338123  1.33253985 -0.21364445\n",
      "  1.00585722 -0.36286308  0.5708374 ] Bias: 0.4832488373210112\n",
      "Epoch 800/4000 Cost: 0.3852635809919738 Weights: [ 0.54886501  3.26110593  0.5566148   1.03373098  1.59257191  0.79341536\n",
      "  0.64035853  0.37687134  0.92578085  0.10792268  1.32483875 -0.23709158\n",
      "  0.9907841  -0.36941146  0.5686507 ] Bias: 0.49900259787322104\n",
      "Epoch 900/4000 Cost: 0.3849324963396387 Weights: [ 0.5597073   3.43330678  0.53648997  1.02880966  1.63689868  0.78573159\n",
      "  0.63199412  0.37439121  0.916977    0.10341964  1.31583282 -0.25209148\n",
      "  0.97797712 -0.37266512  0.56690015] Bias: 0.512673950775279\n",
      "Epoch 1000/4000 Cost: 0.3846855146754661 Weights: [ 0.57151481  3.58220287  0.51789611  1.02487991  1.67424726  0.77922009\n",
      "  0.62479979  0.37306749  0.9093367   0.0996402   1.30599954 -0.26054703\n",
      "  0.96698703 -0.37380816  0.56548763] Bias: 0.5246556539708966\n",
      "Epoch 1100/4000 Cost: 0.3844999431295503 Weights: [ 0.58408846  3.711141    0.50055747  1.02174937  1.70580659  0.77365493\n",
      "  0.618549    0.37267289  0.90263437  0.09645573  1.29572369 -0.26397395\n",
      "  0.95745356 -0.37363048  0.56434707] Bias: 0.535274470708427\n",
      "Epoch 1200/4000 Cost: 0.3843594993851189 Weights: [ 0.59727319  3.82295555  0.48425401  1.01926729  1.73254525  0.76885853\n",
      "  0.61306379  0.37302931  0.89669289  0.09376594  1.28529688 -0.2635841\n",
      "  0.94909226 -0.37266048  0.56342662] Bias: 0.5447871386695726\n",
      "Epoch 1300/4000 Cost: 0.3842524195249268 Weights: [ 0.61094843  3.92005229  0.46880998  1.01731561  1.75525528  0.7646914\n",
      "  0.60820441  0.37399733  0.89137327  0.09148903  1.27493688 -0.26034422\n",
      "  0.94167845 -0.37124889  0.56268479] Bias: 0.5533952840904561\n",
      "Epoch 1400/4000 Cost: 0.3841701487797611 Weights: [ 0.62501988  4.00447756  0.45408413  1.01580116  1.77458675  0.76104317\n",
      "  0.60386032  0.37546703  0.88656565  0.08955786  1.26480376 -0.25502298\n",
      "  0.93503422 -0.36962538  0.56208819] Bias: 0.5612584088034778\n",
      "Epoch 1500/4000 Cost: 0.3841064277330057 Weights: [ 0.63941316  4.07797552  0.43996206  1.01464973  1.7910752   0.75782572\n",
      "  0.59994336  0.37735101  0.88218244  0.08791714  1.25501244 -0.248229\n",
      "  0.9290183  -0.36793732  0.56160982] Bias: 0.568503752435188\n",
      "Epoch 1600/4000 Cost: 0.3840566495409337 Weights: [ 0.65406917  4.14203566  0.4263505   1.0138017   1.80516358  0.75496814\n",
      "  0.59638261  0.3795792   0.87815322  0.08652111  1.24564253 -0.24044175\n",
      "  0.92351826 -0.36627645  0.56122781] Bias: 0.5752336812380032\n",
      "Epoch 1700/4000 Cost: 0.3840174045475724 Weights: [ 0.66894058  4.19793238  0.41317287  1.01320867  1.81721977  0.75241286\n",
      "  0.59312058  0.38209495  0.87442091  0.08533177  1.23674611 -0.23203649\n",
      "  0.91844445 -0.36469716  0.56092432] Bias: 0.5815312312349765\n",
      "Epoch 1800/4000 Cost: 0.38398615551723264 Weights: [ 0.68398919  4.24675794  0.40036594  1.0128311   1.82755044  0.75011279\n",
      "  0.59011026  0.38485213  0.87093886  0.08431747  1.228354   -0.22330449\n",
      "  0.91372523 -0.36322897  0.56068484] Bias: 0.587464288448222\n",
      "Epoch 1900/4000 Cost: 0.38396100457626126 Weights: [ 0.69918396  4.2894501   0.38787717  1.01263635  1.83641221  0.7480291\n",
      "  0.58731295  0.38781285  0.86766867  0.08345173  1.22048064 -0.21446947\n",
      "  0.90930328 -0.36188523  0.56049746] Bias: 0.5930887629466528\n",
      "Epoch 2000/4000 Cost: 0.38394052497862835 Weights: [ 0.71449952  4.32681527  0.37566267  1.01259734  1.84402056  0.74612957\n",
      "  0.58469657  0.39094581  0.86457852  0.08271233  1.21312807 -0.20570097\n",
      "  0.90513271 -0.36066888  0.56035246] Bias: 0.5984510172968242\n",
      "Epoch 2100/4000 Cost: 0.38392363897821896 Weights: [ 0.72991498  4.35954798  0.36368564  1.01269139  1.85055702  0.74438729\n",
      "  0.58223438  0.39422499  0.86164185  0.08208061  1.20628905 -0.19712511\n",
      "  0.90117672 -0.35957649  0.56024187] Bias: 0.6035897394504434\n",
      "Epoch 2200/4000 Cost: 0.38390952868807426 Weights: [ 0.74541305  4.38824729  0.35191504  1.01289946  1.85617499  0.74277962\n",
      "  0.57990391  0.39762859  0.85883638  0.08154081  1.19994949 -0.18883346\n",
      "  0.89740576 -0.35860089  0.56015914] Bias: 0.6085373990010049\n",
      "Epoch 2300/4000 Cost: 0.3838975706722942 Weights: [ 0.76097935  4.41343067  0.34032465  1.01320541  1.86100443  0.74128749\n",
      "  0.57768623  0.4011383   0.85614332  0.08107962  1.19409048 -0.18089016\n",
      "  0.89379613 -0.35773295  0.56009893] Bias: 0.6133213888285853\n",
      "Epoch 2400/4000 Cost: 0.38388728770449276 Weights: [ 0.77660186  4.43554569  0.32889218  1.01359553  1.86515577  0.73989466\n",
      "  0.57556531  0.40473864  0.85354674  0.08068579  1.18868978 -0.17333771\n",
      "  0.89032874 -0.35696276  0.56005683] Bias: 0.6179649274439261\n",
      "Epoch 2500/4000 Cost: 0.38387831300815717 Weights: [ 0.7922705   4.45498     0.31759866  1.0140581   1.86872302  0.73858734\n",
      "  0.57352749  0.40841648  0.85103308  0.08034973  1.18372304 -0.16620168\n",
      "  0.88698824 -0.35628029  0.56002925] Bias: 0.6224877779509475\n",
      "Epoch 2600/4000 Cost: 0.3838703636188891 Weights: [ 0.80797676  4.4720698   0.30642788  1.01458309  1.87178643  0.73735371\n",
      "  0.57156112  0.41216062  0.84859077  0.08006332  1.17916473 -0.15949449\n",
      "  0.88376225 -0.35567592  0.56001323] Bias: 0.6269068254045231\n",
      "Epoch 2700/4000 Cost: 0.3838632204462698 Weights: [ 0.82371348  4.48710699  0.29536599  1.01516187  1.8744146   0.73618361\n",
      "  0.5696562   0.41596148  0.84620988  0.07981962  1.17498887 -0.15321848\n",
      "  0.88064075 -0.35514064  0.56000637] Bias: 0.6312365439760916\n",
      "Epoch 2800/4000 Cost: 0.3838567132804397 Weights: [ 0.83947455  4.50034535  0.28440108  1.01578696  1.87666631  0.73506832\n",
      "  0.56780417  0.41981088  0.84388186  0.07961273  1.17116957 -0.1473684\n",
      "  0.87761562 -0.3546662   0.56000669] Bias: 0.6354893777047371\n",
      "Epoch 2900/4000 Cost: 0.3838507094657818 Weights: [ 0.8552548   4.51200575  0.27352291  1.01645194  1.878592    0.73400031\n",
      "  0.5659976   0.42370175  0.84159936  0.07943758  1.16768144 -0.14193335\n",
      "  0.87468022 -0.35424514  0.5600126 ] Bias: 0.6396760529563701\n",
      "Epoch 3000/4000 Cost: 0.3838451053071132 Weights: [ 0.87104982  4.52228065  0.26272268  1.01715121  1.88023502  0.73297305\n",
      "  0.56423013  0.427628    0.83935601  0.07928986  1.16449987 -0.13689835\n",
      "  0.87182912 -0.3538708   0.56002278] Bias: 0.6438058365013635\n",
      "Epoch 3100/4000 Cost: 0.38383981952146606 Weights: [ 0.88685585  4.53133796  0.25199277  1.01787992  1.88163271  0.7319809\n",
      "  0.56249621  0.4315844   0.83714633  0.07916586  1.16160128 -0.13224565\n",
      "  0.86905783 -0.35353728  0.56003617] Bias: 0.6478867499648774\n",
      "Epoch 3200/4000 Cost: 0.3838347882282122 Weights: [ 0.90266965  4.53932429  0.24132663  1.01863383  1.88281724  0.73101894\n",
      "  0.56079107  0.43556639  0.83496552  0.07906238  1.15896322 -0.12795564\n",
      "  0.86636259 -0.35323938  0.56005193] Bias: 0.6519257490247934\n",
      "Epoch 3300/4000 Cost: 0.3838299611012146 Weights: [ 0.91848848  4.54636779  0.23071857  1.01940928  1.88381638  0.73008292\n",
      "  0.55911053  0.43957005  0.83280944  0.07897671  1.15656449 -0.12400769\n",
      "  0.86374022 -0.35297253  0.56006936] Bias: 0.65592887392715\n",
      "Epoch 3400/4000 Cost: 0.38382529840254315 Weights: [ 0.93430997  4.55258063  0.22016366  1.02020306  1.88465415  0.72916911\n",
      "  0.55745099  0.44359195  0.83067448  0.07890647  1.15438516 -0.1203807\n",
      "  0.86118801 -0.35273274  0.56008791] Bias: 0.6599013765106165\n",
      "Epoch 3500/4000 Cost: 0.38382076868778015 Weights: [ 0.95013209  4.55806105  0.20965764  1.02101235  1.88535134  0.72827429\n",
      "  0.5558093   0.44762913  0.82855751  0.07884964  1.15240661 -0.11705357\n",
      "  0.85870358 -0.35251655  0.56010714] Bias: 0.6638478278719833\n",
      "Epoch 3600/4000 Cost: 0.38381634702501194 Weights: [ 0.9659531   4.56289518  0.19919682  1.02183472  1.88592593  0.72739562\n",
      "  0.55418271  0.45167901  0.82645578  0.07880447  1.15061147 -0.11400557\n",
      "  0.85628483 -0.35232092  0.5601267 ] Bias: 0.6677722099845448\n",
      "Epoch 3700/4000 Cost: 0.3838120136082439 Weights: [ 0.9817715   4.5671586   0.18877798  1.02266802  1.88639355  0.72653065\n",
      "  0.55256885  0.45573934  0.82436692  0.07876944  1.14898366 -0.11121655\n",
      "  0.85392986 -0.35214323  0.56014631] Bias: 0.6716779939421277\n",
      "Epoch 3800/4000 Cost: 0.3838077526747743 Weights: [ 0.99758601  4.57091773  0.17839832  1.0235104   1.88676777  0.72567722\n",
      "  0.55096563  0.45980818  0.82228883  0.07874324  1.14750828 -0.10866717\n",
      "  0.85163694 -0.35198119  0.56016576] Bias: 0.6755682069999537\n",
      "Epoch 3900/4000 Cost: 0.3838035516576281 Weights: [ 1.01339551  4.57423092  0.16805542  1.0243602   1.88706036  0.72483345\n",
      "  0.54937123  0.46388382  0.82021971  0.07872474  1.1461716  -0.10633895\n",
      "  0.84940444 -0.35183284  0.5601849 ] Bias: 0.6794454901872071\n",
      "Epoch 4000/4000 Cost: 0.3837994005203627 Weights: [ 1.02919907  4.57714955  0.15774718  1.02521601  1.88728159  0.72399769\n",
      "  0.54778407  0.46796478  0.81815796  0.07871295  1.14496098 -0.10421445\n",
      "  0.84723084 -0.35169644  0.56020359] Bias: 0.6833121479508393\n",
      "Accuracy: 87.70491803278688% False Negatives: 95.55555555555556% False Positives: 0.6230529595015576%\n"
     ]
    }
   ],
   "source": [
    "model = logistic_regression(X_train_scaled)\n",
    "model.fit(X_train_scaled,Y_train,1,4000)\n",
    "model.accuracy(X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "general_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
